import csv
import re
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

def get_detail_info(driver_detail, link):
    driver_detail.get(link)
    time.sleep(2)
    detail_info = {"ì£¼ìš”ì—…ë¬´": "ì—†ìŒ", "ìê²©ìš”ê±´": "ì—†ìŒ"}
    try:
        dt_elements = driver_detail.find_elements(By.CSS_SELECTOR, "dt.sc-e76d2562-1")
        for dt in dt_elements:
            heading = dt.text.strip()
            if heading in detail_info:
                parent = dt.find_element(By.XPATH, "..")
                pre = parent.find_element(By.TAG_NAME, "pre")
                detail_info[heading] = pre.text.strip()
    except:
        pass
    return detail_info

job_list = []
base_url = "https://jumpit.saramin.co.kr"
keyword = "í’€ìŠ¤íƒê°œë°œì"  # ê²€ìƒ‰ì–´ëŠ” í•œê¸€ë¡œë§Œ

# ë“œë¼ì´ë²„ ì´ˆê¸°í™”
driver_main = webdriver.Chrome(service=Service(ChromeDriverManager().install()))
driver_detail = webdriver.Chrome(service=Service(ChromeDriverManager().install()))

# âœ… 1~3í˜ì´ì§€ ìˆœíšŒ
for page in range(1, 4):
    print(f"ğŸ“„ í’€ìŠ¤íƒ (í•œê¸€+ì˜ì–´) - í˜ì´ì§€ {page}")
    url = f"{base_url}/search?sort=relation&keyword={keyword}&page={page}"
    driver_main.get(url)
    time.sleep(3)

    cards = driver_main.find_elements(By.CSS_SELECTOR, "a[href^='/position/']")

    for card in cards:
        try:
            title_elem = card.find_element(By.CSS_SELECTOR, "h2.position_card_info_title")
            full_title = title_elem.text.strip().replace("\n", " ")

            company_match = re.search(r'\[(.*?)\]', full_title)
            company = company_match.group(1) if company_match else "íšŒì‚¬ëª… ì—†ìŒ"
            title = full_title.replace(f"[{company}]", "").strip()

            # âœ… ì œëª©ì— 'í’€ìŠ¤íƒ' ë˜ëŠ” 'full stack' í¬í•¨ ì—¬ë¶€ ì²´í¬
            title_lower = title.lower()
            if 'í’€ìŠ¤íƒ' in title_lower or 'full stack' in title_lower:
                href = card.get_attribute("href")
                if not href.startswith("http"):
                    href = base_url + href

                skill_items = card.find_elements(By.CSS_SELECTOR, "ul.sc-15ba67b8-1.iFMgIl li")
                skills = [skill.text.strip() for skill in skill_items]

                detail = get_detail_info(driver_detail, href)
                main_task = detail["ì£¼ìš”ì—…ë¬´"]
                qualification = detail["ìê²©ìš”ê±´"]

                print(f"âœ… {company} / {title}")
                job_list.append([
                    company,
                    "í’€ìŠ¤íƒ ê°œë°œì",
                    title,
                    href,
                    ", ".join(skills),
                    main_task,
                    qualification
                ])

        except Exception as e:
            print(f"âŒ ì˜ˆì™¸ ë°œìƒ: {e}")

driver_main.quit()
driver_detail.quit()

# âœ… CSV ì €ì¥
with open("jumpit_fullstack_all.csv", "w", newline="", encoding="utf-8-sig") as f:
    writer = csv.writer(f)
    writer.writerow(["íšŒì‚¬ëª…", "ê³µê³ ", "ì œëª©", "ë§í¬", "ê¸°ìˆ  ìŠ¤íƒ", "ì£¼ìš”ì—…ë¬´", "ìê²©ìš”ê±´"])
    writer.writerows(job_list)

print("ğŸ“„ í’€ìŠ¤íƒ(í•œê¸€+ì˜ì–´) CSV ì €ì¥ ì™„ë£Œ: jumpit_fullstack_all.csv")
